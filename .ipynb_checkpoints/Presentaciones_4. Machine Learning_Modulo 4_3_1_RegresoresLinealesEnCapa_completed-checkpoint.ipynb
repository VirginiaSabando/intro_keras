{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"res/itm_logo.jpg\" width=\"300px\">\n",
    "\n",
    "## Inteligencia Artificial - IAI84\n",
    "### Instituto Tecnológico Metropolitano\n",
    "#### Pedro Atencio Ortiz - 2018\n",
    "\n",
    "En este notebook se aborda el tema de aprendizaje de máquina para clasificación binaria no-lineal utilizando Regresores logísticos en cadena:\n",
    "1. El problema XOR\n",
    "2. Regresores logísticos en cadena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# 1. El problema XOR\n",
    "\n",
    "<img src='res/shallow_nn/xor_problem.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 1. Regresor Logístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation(W, b, X):\n",
    "    z = np.dot(W.T,X) + b\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    '''\n",
    "    Returns sigmoid activation for array z\n",
    "    '''\n",
    "    a = 1. / (1. + np.exp(-z)) \n",
    "    \n",
    "    return a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, a):\n",
    "    return -(y * np.log(a) + (1-y) * np.log(1-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(logloss):\n",
    "    return np.mean(logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Trabajemos\n",
    "3. Realicemos descenso del gradiente por cada regresor logístico.\n",
    "4. Creemos un solo regresor no lineal combinando el grafo de cómputo en cadena visto en clase y los W y b actualizados para cada regresor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Creemos los 3 datasets (X1, Y1), (X2, Y2) y (X3, Y3) según trabajamos en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1:  [[0 0 1 1]\n",
      " [0 1 0 1]] Y1:  [[0 1 1 1]]\n",
      "X2:  [[0 0 1 1]\n",
      " [0 1 0 1]] Y2:  [[1 1 1 0]]\n",
      "X3:  [[0 1 1 1]\n",
      " [1 1 1 0]] Y3:  [[0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([[0,0],[0,1],[1,0],[1,1]]).T\n",
    "Y1 = np.array([[0, 1, 1, 1]])\n",
    "print(\"X1: \",X1, 'Y1: ', Y1)\n",
    "\n",
    "X2 = np.array([[0,0],[0,1],[1,0],[1,1]]).T\n",
    "Y2 = np.array([[1, 1, 1, 0]])\n",
    "print(\"X2: \",X2, 'Y2: ', Y2)\n",
    "\n",
    "X3 = np.array([[0,1],[1,1],[1,1],[1,0]]).T\n",
    "Y3 = np.array([[0, 1, 1, 0]])\n",
    "print(\"X3: \",X3, 'Y3: ', Y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Resultado esperado:__<br>\n",
    "('X1: ', array([[0, 0, 1, 1],\n",
    "       [0, 1, 0, 1]]), 'Y1: ', array([[0, 1, 1, 1]]))\n",
    "       <br>\n",
    "('X2: ', array([[0, 0, 1, 1],\n",
    "       [0, 1, 0, 1]]), 'Y2: ', array([[1, 1, 1, 0]]))\n",
    "       <br>\n",
    "('X3: ', array([[0, 1, 1, 1],\n",
    "       [1, 1, 1, 0]]), 'Y3: ', array([[0, 1, 1, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Inicialicemos los pesos W1, W2, W3 de forma aleatoria (__np.random.rand(shape)__) y los bias b en zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:  [[-0.41675785]\n",
      " [-0.05626683]] b1:  0\n",
      "W2:  [[-2.1361961 ]\n",
      " [ 1.64027081]] b2:  0\n",
      "W3:  [[-1.79343559]\n",
      " [-0.84174737]] b3:  0\n"
     ]
    }
   ],
   "source": [
    "def initialize_parameters():\n",
    "    seed = 2\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    W1 = np.random.randn(2,1)\n",
    "    b1 = 0\n",
    "\n",
    "    W2 = np.random.randn(2,1)\n",
    "    b2 = 0\n",
    "\n",
    "    W3 = np.random.randn(2,1)\n",
    "    b3 = 0\n",
    "\n",
    "    return (W1, b1, W2, b2, W3, b3)\n",
    "\n",
    "(W1,b1,W2,b2,W3,b3) = initialize_parameters()\n",
    "\n",
    "print('W1: ', W1, 'b1: ',b1)\n",
    "print('W2: ', W2, 'b2: ',b2)\n",
    "print('W3: ', W3, 'b3: ',b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Resultado esperado:__\n",
    "<br>\n",
    "('W1: ', array([[-0.41675785],\n",
    "       [-0.05626683]]), 'b1: ', 0)\n",
    "       <br>\n",
    "('W2: ', array([[-2.1361961 ],\n",
    "       [ 1.64027081]]), 'b2: ', 0)\n",
    "       <br>\n",
    "('W3: ', array([[-1.79343559],\n",
    "       [-0.84174737]]), 'b3: ', 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "### - Apliquemos descenso del gradiente a cada regresor logístico por separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(A, X, Y):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    dz = A - Y\n",
    "    dW = np.dot(X, dz.T) / m\n",
    "    db = np.sum(dz) / m\n",
    "    \n",
    "    return (dW, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costo regresor 1 -- iteracion  0 :  0.8238191909273627\n",
      "costo regresor 2 -- iteracion  0 :  0.8984606515897027\n",
      "costo regresor 3 -- iteracion  0 :  0.8984606515897027\n",
      "costo regresor 1 -- iteracion  1000 :  0.015684525863179696\n",
      "costo regresor 2 -- iteracion  1000 :  0.02884491516543498\n",
      "costo regresor 3 -- iteracion  1000 :  0.02884491516543498\n",
      "costo regresor 1 -- iteracion  2000 :  0.007734070046997761\n",
      "costo regresor 2 -- iteracion  2000 :  0.014481348596109028\n",
      "costo regresor 3 -- iteracion  2000 :  0.014481348596109028\n",
      "costo regresor 1 -- iteracion  3000 :  0.005120140083221766\n",
      "costo regresor 2 -- iteracion  3000 :  0.009633470445720167\n",
      "costo regresor 3 -- iteracion  3000 :  0.009633470445720167\n",
      "costo regresor 1 -- iteracion  4000 :  0.003823970609968419\n",
      "costo regresor 2 -- iteracion  4000 :  0.007209259287853589\n",
      "costo regresor 3 -- iteracion  4000 :  0.007209259287853589\n",
      "costo regresor 1 -- iteracion  5000 :  0.003050506087749796\n",
      "costo regresor 2 -- iteracion  5000 :  0.005756967847574197\n",
      "costo regresor 3 -- iteracion  5000 :  0.005756967847574197\n",
      "costo regresor 1 -- iteracion  6000 :  0.0025368672755381955\n",
      "costo regresor 2 -- iteracion  6000 :  0.004790430024652249\n",
      "costo regresor 3 -- iteracion  6000 :  0.004790430024652249\n",
      "costo regresor 1 -- iteracion  7000 :  0.002171056834975206\n",
      "costo regresor 2 -- iteracion  7000 :  0.004101141664614222\n",
      "costo regresor 3 -- iteracion  7000 :  0.004101141664614222\n",
      "costo regresor 1 -- iteracion  8000 :  0.0018973287509570043\n",
      "costo regresor 2 -- iteracion  8000 :  0.0035849045026744002\n",
      "costo regresor 3 -- iteracion  8000 :  0.0035849045026744002\n",
      "costo regresor 1 -- iteracion  9000 :  0.0016848237259386941\n",
      "costo regresor 2 -- iteracion  9000 :  0.0031838848261483135\n",
      "costo regresor 3 -- iteracion  9000 :  0.0031838848261483135\n",
      "W1 actualizado:  [[12.30162845]\n",
      " [12.30163466]] b1 actualizado:  -5.6915448639261275\n",
      "W2 actualizado:  [[-11.0458057]\n",
      " [-11.0458057]] b2 actualizado:  16.73764220182091\n",
      "W3 actualizado:  [[11.73297854]\n",
      " [11.73297854]] b3 actualizado:  -17.4206074745061\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.6\n",
    "\n",
    "(W1,b1,W2,b2,W3,b3) = initialize_parameters()\n",
    "\n",
    "num_epochs = 10000\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    ## Forward Propagation\n",
    "    Z1 = linear_activation(W1,b1,X1)\n",
    "    A1 = sigmoid(Z1)\n",
    "    \n",
    "    Z2 = linear_activation(W2,b2,X2)\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    Z3 = linear_activation(W3,b3,X3)\n",
    "    A3 = sigmoid(Z3)\n",
    "    \n",
    "    #Backward Propagation\n",
    "    (dW1, db1) = backward_propagation(A1,X1, Y1)\n",
    "    (dW2, db2) = backward_propagation(A2,X2, Y2)\n",
    "    (dW3, db3) = backward_propagation(A3,X3, Y3)\n",
    "    \n",
    "    #Weight Updates\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    W3 -= learning_rate * dW3\n",
    "    b3 -= learning_rate * db3\n",
    "    \n",
    "    #Cost estimation\n",
    "    J1 = cost(loss(Y1,A1))\n",
    "    J2 = cost(loss(Y2,A2))\n",
    "    J3 = cost(loss(Y3,A3))\n",
    "    \n",
    "    \n",
    "    if(i%1000 == 0):\n",
    "        print(\"costo regresor 1 -- iteracion \", i, \": \", J1)\n",
    "        print(\"costo regresor 2 -- iteracion \", i, \": \", J2)\n",
    "        print(\"costo regresor 3 -- iteracion \", i, \": \", J2)\n",
    "\n",
    "print(\"W1 actualizado: \",W1, \"b1 actualizado: \", b1)\n",
    "print(\"W2 actualizado: \",W2, \"b2 actualizado: \", b2)\n",
    "print(\"W3 actualizado: \",W3, \"b3 actualizado: \", b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Resultado esperado:__\n",
    "<br>\n",
    "('costo regresor 1 -- iteracion ', 0, ': ', 0.82381919092736267)\n",
    "<br>\n",
    "('costo regresor 2 -- iteracion ', 0, ': ', 1.690717816357759)\n",
    "<br>\n",
    "('costo regresor 3 -- iteracion ', 0, ': ', 1.690717816357759)\n",
    "<br>\n",
    "...\n",
    "<br>\n",
    "('costo regresor 1 -- iteracion ', 1800, ': ', 0.059067083863525841)\n",
    "<br>\n",
    "('costo regresor 2 -- iteracion ', 1800, ': ', 0.43458474800401775)\n",
    "<br>\n",
    "('costo regresor 3 -- iteracion ', 1800, ': ', 0.43458474800401775)\n",
    "<br><br>\n",
    "('W1 actualizado: ', array([[ 3.63883826],\n",
    "       [ 3.99932928]]), 'b1 actualizado: ', -1.2304228512033604)\n",
    "       <br>\n",
    "('W2 actualizado: ', array([[-4.46040679],\n",
    "       [-0.68393989]]), 'b2 actualizado: ', 4.440351150899609)\n",
    "       <br>\n",
    "('W3 actualizado: ', array([[ 1.97706174],\n",
    "       [ 2.92874996]]), 'b3 actualizado: ', -3.3939910248821952)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - verifiquemos las predicciones por cada regresor logístico ya entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W,b,X):\n",
    "    z = linear_activation(W,b,X)\n",
    "    A = sigmoid(z)\n",
    "    return np.round(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicciones regresor 1:  [[0. 1. 1. 1.]] --- Clases originales:  [[0 1 1 1]]\n",
      "predicciones regresor 2:  [[1. 1. 1. 0.]] --- Clases originales:  [[1 1 1 0]]\n",
      "predicciones regresor 3:  [[0. 1. 1. 0.]] --- Clases originales:  [[0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "Y_hat1 = predict(W1,b1,X1)\n",
    "Y_hat2 = predict(W2,b2,X2)\n",
    "Y_hat3 = predict(W3,b3,X3)\n",
    "print(\"predicciones regresor 1: \",np.round(Y_hat1),\"--- Clases originales: \", Y1)\n",
    "print(\"predicciones regresor 2: \",np.round(Y_hat2),\"--- Clases originales: \", Y2)\n",
    "print(\"predicciones regresor 3: \",np.round(Y_hat3),\"--- Clases originales: \", Y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Resultado esperado:__\n",
    "<br>\n",
    "('predicciones regresor 1: ', array([[ 0.,  1.,  1.,  1.]]), '--- Clases originales: ', array([[0, 1, 1, 1]]))\n",
    "<br>\n",
    "('predicciones regresor 2: ', array([[ 1.,  1.,  1.,  0.]]), '--- Clases originales: ', array([[1, 1, 1, 0]]))\n",
    "<br>\n",
    "('predicciones regresor 3: ', array([[ 0.,  1.,  1.,  0.]]), '--- Clases originales: ', array([[0, 1, 1, 0]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "### - Agrupemos los tres regresores en capas\n",
    "<img src='res/shallow_nn/compute_graph_3.png' width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def predict_multilayer(W1,b1,W2,b2,W3,b3,X):\n",
    "    Z1 = linear_activation(W1,b1,X)\n",
    "    A1 = sigmoid(Z1)\n",
    "    \n",
    "    Z2 = linear_activation(W2,b2,X)\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    X3 = np.concatenate((A1,A2), axis=0)\n",
    "    Z3 = linear_activation(W3, b3, X3)\n",
    "    A3 = sigmoid(Z3)\n",
    "    \n",
    "    return np.round(A3)\n",
    "\n",
    "y_hat = predict_multilayer(W1,b1,W2,b2,W3,b3,X1)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apliquemos nuestro regresor multicapa al problema XOR\n",
    "----- Solo ejecutar celdas -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([[0, 1, 1, 0]])\n",
    "\n",
    "color= ['blue' if y == 1 else 'red' for y in np.squeeze(Y)]\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(X[:,0], X[:,1], color=color)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_lr(W1, b1, W2, b2, W3, b3, X, Y):\n",
    "    X = X.T\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    Z = predict_multilayer(W1,b1,W2,b2,W3,b3,np.c_[xx.ravel(), yy.ravel()].T)\n",
    "    print(Z)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    \n",
    "    color= ['blue' if y == 1 else 'red' for y in np.squeeze(Y)]\n",
    "    plt.scatter(X[:,0], X[:,1], color=color)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAboAAAEvCAYAAAAzXAR1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAfBElEQVR4nO3dfZBcdZ3v8c9nZvLEUyYhQCJgDCYSWQNB50aFlJIVMbBVhFLvGlyXKFi4e3Wtrei9hqLqegvvlugGUWvdqyk2K3ivIovoZgu5LEJYyw0ogzePIGQIKAmBKJAgJiTMzPf+0WeWzqTnKf2bPqdPv19VXdPnqfM70z35zOk5nz6OCAEAUFZteQ8AAIDxRNABAEqNoAMAlBpBBwAoNYIOAFBqBB0AoNQ68h7A0ZhwzNSYPPXkvIeBEZx5apte3vZc3sMA0AIee2Xf7yLipFrLmjLoJk89WW9b8bW8h4FROP/re/XFH92ijXc15UsNQJM4f+udvx5qGW9dYlxtWtepS9o+rfO2fCbvoQBoUQQdGuKCVQc0ef37tfDi3ryHAqDFEHRomJWrZ3J0B6DhCDo0HEd3ABqJoEMuBo7u3rn27LyHAqDkCDrkaskPFmvy+vfnPQwAJUbQIXcrV8/U97/1YY7uAIwLgg6FsGldp5b8YDEnqgBIjqBDoVyw6oC+/60Pc6IKgGQIOhQOJXMAKRF0KCxqCABSIOhQaNQQANSLoENToIYA4GgRdGga1BAAHA2CDk2FGgKAsSLo0JSoIQAYLYIOTYsaAoDRIOjQ9KghABgOQYdS4Fp3AIZC0KFUOLoDMBhBh9JZuXqmrrnsCmoIACQRdCipgRoCJXMABB1KjZI5AIIOpUfJHGhtBB1aBiVzoDURdGgplMyB1kPQoSVRQwBaR5Kgs73W9h7bW4dY/me2N9veYnuD7XOqlj2Vzd9ouzvFeIDR4Fp3QGtIdUT3bUlLh1n+pKR3R8QCSV+QtGbQ8iURsTAiuhKNBxg1aghAuSUJuoj4qaQXhlm+ISJezCYflHRain8XSIUaAlBeefyN7ipJd1VNh6R/tf2w7atzGA8giRoCUFYNDTrbS1QJus9VzV4cEW+VdLGkT9p+1xDbXm2723b3q/v3NWC0aFXUEIByaVjQ2T5b0k2SlkXE8wPzI2JX9nWPpB9KWlRr+4hYExFdEdE14ZipjRgyWhg1BKA8GhJ0tl8v6Q5Jfx4Rj1fNP9b28QP3JV0kqeaZm0AeqCEAza8jxYPY/p6kCyTNsL1T0uclTZCkiPimpP8u6URJf29bknqzMyxPkfTDbF6HpO9GxP9NMSYglZWrZ0ptn9b6tT/TA1duzns4AMYoSdBFxOUjLP+4pI/XmL9D0jlHbgEUz5IfLNZX1s/V/C/fpo13JfnRAdAAfDIKMAZc6w5oPgQdMEZc6w5oLgQdcJQomQPNgaAD6kDJHCg+gg5IgJI5UFwEHZAIJXOgmAg6IDFK5kCxEHTAOOBad0BxEHTAOKKGAOSPoAPGGTUEIF8EHdAA1BCA/BB0QANRQwAaj6ADGowaAtBYBB2QE2oIQGMQdECOqCEA44+gAwpgoIbA0R2QHkEHFATXugPGB0EHFAjXugPSI+iAAqJkDqRD0AEFRckcSIOgAwqOkjlQH4IOaAKUzIGjR9ABTYSSOTB2BB3QZCiZA2ND0AFNihoCMDpJgs72Wtt7bG8dYrltf912j+3Ntt9atWyF7e3ZbUWK8WB8vfTMVPXcO1871p+pl587Pu/htDRqCPmbeOiATt2zXXOe2appLz0nReQ9JAzSkehxvi3p7yTdMsTyiyXNy25vl/S/JL3d9nRJn5fUJSkkPWx7XUS8mGhcSKzn3vnavfH16u9tlxza9cs36PXv7NHs857Ie2gta9O6Ti3RYt2/5b3asOCGvIfTUjp/v0dn/uaXkkLt0a+T9u7UHyafoEfe8A5FG2+YFUWSZyIifirphWFWWSbplqh4UFKn7VmS3ifpnoh4IQu3eyQtTTEmpPf7Z0/Q7o2z1d/bIclStKm/t12/2TBXB/ZOyXt4LY8aQmM5+vWmpzeqPfrUHv2SpI7+Ph13YJ9OfvE3OY8O1Rr1K8epkp6umt6ZzRtqPgrod9tPUX+fj5gfkp7vObnxA8IRqCE0zrEH9qny6j9ce/TrpH3PNH5AGFLTHFvbvtp2t+3uV/fvy3s4LamtvV8+Mudkh9ra+btEkVBDGH/hNrlG0ElSv5vmv9aW0KhnY5ek06umT8vmDTX/CBGxJiK6IqJrwjFTx22gGNrJb94tt9X6wbZmvOnZho8Hw6OGML7+MPkE9bZNOCLq+tyu56a/PpcxobZGBd06SVdkZ1++Q9K+iNgt6W5JF9meZnuapIuyeSigKdP2643veURt7X1qm9BbuXX06cxLNmnisYfyHh6GwLXuxomtR2d3qbd9gnrbOtTnNvW5Tb+b+jo9f8KsvEeHKknOurT9PUkXSJphe6cqZ1JOkKSI+KakH0u6RFKPpP2SPpYte8H2FyQ9lD3UdREx3EktyNnrFj6tGfOe0/M9J8ttoRPn7tGEKa/mPSyMYOXqmTrnsiv01f+8VQ9cuTnv4ZTG/ilT1X3mezT993vU0XdILx17og5MOi7vYWEQRxN2Po6fNS/etuJreQ8DaEpf+eyzemXJHXkPA0jq/K13PhwRXbWW8RdToMVQMkerIeiAFsS17tBKmjLozux8WedcujfvYQBNj5I5WkFTBt3LTx3Qhz7xXX3ls5zSDtSLkjnKrimDbsArS+7Q+g/8LO9hAKVAyRxl1dRBJ0kPXLlZP+7/Okd3QAKUzFFGTR90krTxrg69suQO3X89HywMpMC17lAmpQi6ARsW3KAf93+dE1WABKghoCxKFXRS5ejuQ5/4Lkd3QALUEFAGpQu6ARsW3KD1H/gZR3dAAtQQ0MxKG3RS5UQVaghAGtQQ0KxKHXQDqCEA6VBDQLNpiaCTqCEAKVFDQDNpmaCTqCEAqXGtOzSDlgq6AdQQgHRWrp6pay67gqM7FFZLBp1EDQFIiRoCiqxlg24ANQQgnYEaAkd3KJKWDzrptRoCR3dA/Ti6Q9EQdFU4ugPSoWSOoiDoBqFkDqRDyRxFQNANgZI5kA4lc+SJoBsGJXMgHUrmyAtBNwJK5kBaXOsOjUbQjRIlcyAdrnWHRiLoxoCSOZAONQQ0SpKgs73U9mO2e2yvqrH8Rtsbs9vjtvdWLeurWrYuxXjGGzUEIB1qCBhvjoj6HsBul/S4pPdK2inpIUmXR8QjQ6z/V5LOjYgrs+mXI+K4sfyb86d0xtq5i+sadyqT179fK1fPzHsYQCncf/0UbVhwQ97DQBM6f+udD0dEV61lKY7oFknqiYgdEXFI0q2Slg2z/uWSvpfg3y0EaghAOtQQMB5SBN2pkp6umt6ZzTuC7dmS5ki6r2r2ZNvdth+0fVmC8TQcNQQgHWoISK3RJ6Msl3R7RPRVzZudHW5+WNJXbb+x1oa2r84CsXtv36FGjHVMqCEAaVFDQCopgm6XpNOrpk/L5tWyXIPetoyIXdnXHZLul3RurQ0jYk1EdEVEV2f7xHrHPG6oIQDpUENACimC7iFJ82zPsT1RlTA74uxJ2/MlTZP0QNW8abYnZfdnSDpfUs2TWJoJNQQgHWoIqFfdQRcRvZI+JeluSY9Kui0ittm+zvalVasul3RrHH6a55slddveJGm9pOuHOluzGVFDANLhWnc4WnXXC/JQpHrBaJ235TO6YNWBvIcBlAI1BAw23vUCjAJHd0A6lMwxFgRdA3GtOyAdrnWH0SLockDJHEiHkjlGQtDlhJI5kA4lcwyHoMsRJXMgLUrmqIWgKwBK5kA6lMwxGEFXEJTMgXQomaMaQVcw1BCAdKghQCLoCokaApAONQQQdAVGDQFIhxpC6yLoCo4aApAONYTWRNA1AWoIQFrUEFoLQddEqCEA6VBDaB0EXZOhhgCkQw2hNRB0TYoaApAO17orN4KuiQ3UEDi6A+rH0V15EXQlwNEdkA4l8/Ih6ErigSs364s/uoUaApAAJfNyIehKZKCGQMkcSIOSeTkQdCVEyRxIh5J58yPoSoqSOZAWJfPmRdCVHCVzIB1K5s2JoGsBlMyBdKghNB+CroVQQwDSoYbQPAi6FsO17oB0qCE0hyRBZ3up7cds99heVWP5R23/1vbG7PbxqmUrbG/PbitSjAcjo4YApEMNodjqDjrb7ZK+IeliSWdJutz2WTVW/X5ELMxuN2XbTpf0eUlvl7RI0udtT6t3TBgdaghAOtQQiivFEd0iST0RsSMiDkm6VdKyUW77Pkn3RMQLEfGipHskLU0wJowSNQQgLWoIxZMi6E6V9HTV9M5s3mAfsL3Z9u22Tx/jthhn1BCAdKghFEujTkb5F0lviIizVTlqu3msD2D7atvdtrv39h1KPkBQQwBSooZQHCmCbpek06umT8vm/YeIeD4iDmaTN0l622i3rXqMNRHRFRFdne0TEwwbQ6GGAKTDte7ylyLoHpI0z/Yc2xMlLZe0rnoF27OqJi+V9Gh2/25JF9melp2EclE2DzmjhgCkw9FdvuoOuojolfQpVQLqUUm3RcQ229fZvjRb7dO2t9neJOnTkj6abfuCpC+oEpYPSboum4eCGKghcHQH1I8aQj4cEXmPYczmT+mMtXMX5z2MlrLw4l796r/9qVaunpn3UIBSuP/6Kdqw4Ia8h1Ea52+98+GI6Kq1jE9GwahwrTsgLY7uGoegw5hQMgfSoWTeGAQdxoySOZAWJfPxRdDhqFEyB9KhZD5+CDrUhZI5kA41hPFB0CEJSuZAOlzrLi2CDslQMgfS4Vp36RB0SI4aApAONYT6EXQYF9QQgHSoIdSHoMO4oYYApEUN4egQdBh31BCAdKghjB1Bh4aghgCkQw1hbAg6NBQ1BCAdagijQ9Ch4aghAOlQQxgZQYfccK07IB1qCEMj6JCrB67crC/+6BaO7oAEBmoIHN0djqBD7rjWHZAWR3eHI+hQGJTMgXQomb+GoEOhUDIH0qJkTtChoCiZA+m0esmcoENhUTIH0mnlkjlBh8KjZA6k04olc4IOTYGSOZBOq5XMCTo0FWoIQDqtUkMg6NB0qCEA6bRCDYGgQ1OihgCkVeYaQpKgs73U9mO2e2yvqrF8pe1HbG+2fa/t2VXL+mxvzG7rUowHrYMaApBOWWsIdQed7XZJ35B0saSzJF1u+6xBq/0/SV0Rcbak2yV9uWrZgYhYmN0urXc8aD3UEIB0ylhDSHFEt0hST0TsiIhDkm6VtKx6hYhYHxH7s8kHJZ2W4N8FDkMNAUinTDWEFEF3qqSnq6Z3ZvOGcpWku6qmJ9vutv2g7cuG2sj21dl63Xv7DtU3YpQWNQQgnbLUEBp6Mortj0jqkvS3VbNnR0SXpA9L+qrtN9baNiLWRERXRHR1tk9swGjRzLjWHZBOs9cQUgTdLkmnV02fls07jO0LJV0r6dKIODgwPyJ2ZV93SLpf0rkJxgRwrTsgoWa+1l2KoHtI0jzbc2xPlLRc0mFnT9o+V9K3VAm5PVXzp9melN2fIel8SY8kGBMgiWvdAak149Fd3UEXEb2SPiXpbkmPSrotIrbZvs72wFmUfyvpOEn/NKhG8GZJ3bY3SVov6fqIIOiQHCVzIJ2Vq2fqmsuuaJoagiMi7zGM2fwpnbF27uK8h4Emdd6Wz+iCVQfyHgZQCl/57LN6ZckdeQ9D52+98+HsfI8j8MkoaDmUzIF0mqFkTtChJVEyB9IpesmcoENLo2QOpFPUkjlBh5ZHyRxIp4glc4IOyFBDANIpUg2BoAOqUEMA0inKte4IOmAQrnUHpJX3te4IOmAI1BCAdPKsIRB0wDCoIQDp5FVDIOiAUaCGAKTT6BoCQQeMEjUEIJ1G1hAIOmCMuNYdkE4jaggEHXAUuNYdkM541xAIOuAoUUMA0hqoIaQ+uiPogDoN1BA4ugPqNx7XuiPogAQ4ugPSGaghpCqZE3RAQpTMgXRSlcwJOiAxSuZAOilK5gQdME4omQPp1FMyJ+iAcUTJHEjnaEvmBB3QAFzrDkhnrCVzgg5oEK51B6QzlpI5QQc0EDUEIK3R1BAIOiAH1BCAdFaunjnscoIOyAk1BKAxOlI8iO2lkr4mqV3STRFx/aDlkyTdIultkp6X9KGIeCpbdo2kqyT1Sfp0RNydYkwYHxNefUVzdm/T9N/vkST97oRZemrWWertmJjzyJrXhgU3aP3as/XXr75Fm9Z15j0cjEF/n/Xrf5+rZ375BvUeatcJs/Zp7nu36fiZL+U9NFSp+4jOdrukb0i6WNJZki63fdag1a6S9GJEzJV0o6QvZdueJWm5pD+StFTS32ePhwJyf5/OfuLfNf2lZ9UW/WqLfs3Y94zesmODFJH38JoaNYTm9PhdC7TzoTPUe3CCFG166Zlp2vjdd2j/C8fkPTRUSfHW5SJJPRGxIyIOSbpV0rJB6yyTdHN2/3ZJ77HtbP6tEXEwIp6U1JM9HgroxJd2q73v1cNeNG0KTex9RZ0v/za3cZUJNYTmcejlidrzq1nq7z38d/P+3jY9/Ys5OY0KtaQIulMlPV01vTObV3OdiOiVtE/SiaPcFgVxzCsvqyP6jpjf1t+vYw7+PocRlRM1hOaw/8Vj1dbRf+SCaNPLz01t/IAwpKY5GcX21ba7bXfv7TuU93Ba0oFJx6mvxjvL/W1tOjDpuBxGVF7UEIpvyrT96u+t8V+o+3XcyfyNrkhSBN0uSadXTZ+Wzau5ju0OSVNVOSllNNtKkiJiTUR0RURXZzsnPuTh+amz1NveoerfYftlvdoxWS8ed3Ju4yozrnVXXJOOO6iTznxWbR2HfzpHW0e/Tn/7kzmNCrWkCLqHJM2zPcf2RFVOLlk3aJ11klZk9z8o6b6IiGz+ctuTbM+RNE/SLxKMCeOgv61dW954vl48/hT1y+q39fwJM7XljHdKdt7DKy2O7orrzEs269S3/VrtE1+VFDp+1l6ds/znOmb6H/IeGqrUXS+IiF7bn5J0tyr1grURsc32dZK6I2KdpH+Q9B3bPZJeUCUMla13m6RHJPVK+mREjT8CoTAOTZiix2Z3vXaWJQHXMBsW3KAfX9yray67ghpCQbS1h8644DGdccFjiuDHoagcTXha+PwpnbF27uK8hwHk5rwtn9EFqw7kPQygMP7tS3/ycER01VrWNCejAHgN17oDRo+gA5oUJXNgdAg6oMlRMgeGR9ABJUDJHBgaQQeUBDUEoDaCDigZrnUHHI6gA0qIa90BryHogBKjhgAQdEDpUUNAqyPogBZBDQGtiqADWgg1BLQigg5oMdQQ0GoIOqBFca07tAqCDmhhHN2hFRB0AKghoNQIOgCSXqshcHSHsiHoAByGozuUDUEH4AiUzFEmBB2AIVEyRxkQdACGRckczY6gAzAiaghoZgQdgFHjWndoRgQdgDHhWndoNgQdgKNCDQHNgqADcNSoIaAZ1BV0tqfbvsf29uzrtBrrLLT9gO1ttjfb/lDVsm/bftL2xuy2sJ7xAMgHNQQUWb1HdKsk3RsR8yTdm00Ptl/SFRHxR5KWSvqq7c6q5f81IhZmt411jgdATqghoKjqDbplkm7O7t8s6bLBK0TE4xGxPbv/jKQ9kk6q898FUEDUEFBE9QbdKRGxO7v/rKRThlvZ9iJJEyU9UTX7b7K3NG+0PanO8QAoAK51hyIZMehs/8T21hq3ZdXrRURIimEeZ5ak70j6WET0Z7OvkTRf0n+SNF3S54bZ/mrb3ba79/YdGnnPAOSKozsURcdIK0TEhUMts/2c7VkRsTsLsj1DrHeCpDslXRsRD1Y99sDR4EHb/yjps8OMY42kNZI0f0rnkIEKoFg2LLhB69eerb9+9S3atK5z5A2AxOp963KdpBXZ/RWS/nnwCrYnSvqhpFsi4vZBy2ZlX63K3/e21jkeAAXEte6Qp3qD7npJ77W9XdKF2bRsd9m+KVvnTyW9S9JHa9QI/o/tLZK2SJoh6X/WOR4ABUbJHHlw5U9rzWX+lM5YO3dx3sMAUIfJ69+vlatn5j0MlMS/felPHo6IrlrL+GQUALmgZI5GIegA5IaSORqBoAOQK2oIGG8EHYBC4Fp3GC8EHYDC4Fp3GA8EHYDCoYaAlAg6AIXEte6QCkEHoNCoIaBeBB2AwqOGgHoQdACaAjUEHC2CDkBToYaAsSLoADQdaggYC4IOQNOihoDRIOgANDWudYeREHQASoGjOwyFoANQGpTMUQtBB6B0KJmjGkEHoJQomWMAQQegtCiZQyLoALQASuatjaAD0BIombcugg5AS6GG0HoIOgAthxpCayHoALQsagitgaAD0NKoIZRfXUFne7rte2xvz75OG2K9Ptsbs9u6qvlzbP/cdo/t79ueWM94AOBoUEMot3qP6FZJujci5km6N5uu5UBELMxul1bN/5KkGyNirqQXJV1V53gA4KhRQyineoNumaSbs/s3S7pstBvatqQ/lnT70WwPAOOBGkL51Bt0p0TE7uz+s5JOGWK9yba7bT9oeyDMTpS0NyJ6s+mdkk6tczwAkAQ1hPLoGGkF2z+RNLPGomurJyIibMcQDzM7InbZPkPSfba3SNo3loHavlrS1dnkwfO33rl1LNsX0AxJv8t7EHViH4qBfRgvi+4cy9rF3IexaeZ9mD3UghGDLiIuHGqZ7edsz4qI3bZnSdozxGPsyr7usH2/pHMl/UBSp+2O7KjuNEm7hhnHGklrsn+3OyK6Rhp7kbEPxcA+FAP7UAxl2Ida6n3rcp2kFdn9FZL+efAKtqfZnpTdnyHpfEmPRERIWi/pg8NtDwBAPeoNuuslvdf2dkkXZtOy3WX7pmydN0vqtr1JlWC7PiIeyZZ9TtJK2z2q/M3uH+ocDwAAhxnxrcvhRMTzkt5TY363pI9n9zdIWjDE9jskLTqKf3rNUWxTNOxDMbAPxcA+FEMZ9uEIrryDCABAOfERYACAUits0JXh48VGsw+2F9p+wPY225ttf6hq2bdtP1m1fwsbOPalth/Lvn9HfOKN7UnZ97Un+z6/oWrZNdn8x2y/r1FjrjHGkfZhpe1Hsu/7vbZnVy2r+bpqtFHsw0dt/7ZqrB+vWrYie+1tt71i8LaNMop9uLFq/I/b3lu1LPfnwfZa23ts16w0ueLr2f5ttv3WqmVFeQ5G2oc/y8a+xfYG2+dULXsqm7/RdnfjRp1QRBTyJunLklZl91dJ+tIQ6708xPzbJC3P7n9T0l8WcR8kvUnSvOz+6yTtltSZTX9b0gdzGHe7pCcknSFpoqRNks4atM5/kfTN7P5ySd/P7p+VrT9J0pzscdoLug9LJB2T3f/LgX0Y7nVVwH34qKS/q7HtdEk7sq/TsvvTirgPg9b/K0lrC/Y8vEvSWyVtHWL5JZLukmRJ75D08yI9B6Pch/MGxibp4oF9yKafkjQj7+ehnlthj+hUjo8XG3EfIuLxiNie3X9GlS7iSQ0bYW2LJPVExI6IOCTpVlX2pVr1vt0u6T3Z932ZpFsj4mBEPCmpR0d3wlG9RtyHiFgfEfuzyQdV6XIWyWieh6G8T9I9EfFCRLwo6R5JS8dpnMMZ6z5cLul7DRnZKEXETyW9MMwqyyTdEhUPqtIPnqXiPAcj7kNEbMjGKBXzZ6EuRQ66Mny82Gj3QZJke5Eqv/U+UTX7b7K3FG4c6CM2wKmSnq6arvX9+491su/zPlW+76PZthHGOo6rVPmtfECt11WjjXYfPpC9Rm63ffoYtx1vox5H9tbxHEn3Vc0uwvMwkqH2sSjPwVgN/lkISf9q+2FXPqGq6dRVL6iXC/LxYvVItA/KfgP8jqQVEdGfzb5GlYCcqMppv5+TdF2KceM1tj8iqUvSu6tmH/G6iognaj9Crv5F0vci4qDtT6hylP3HOY/paC2XdHtE9FXNa5bnoRRsL1El6BZXzV6cPQcnS7rH9q+yI8SmkWvQRUE+XqweKfbB9gmS7pR0bfbWx8BjDxwNHrT9j5I+m3Dow9kl6fSq6Vrfv4F1dtrukDRV0vOj3LYRRjUO2xeq8kvJuyPi4MD8IV5Xjf4PdsR9iEqXdcBNqvxdeGDbCwZte3/yEY5sLK+H5ZI+WT2jIM/DSIbax6I8B6Ni+2xVXkMXV7+uqp6DPbZ/qMrb0U0VdEV+67IMHy82mn2YKOmHqrzHf/ugZbOyr1bl73uN+iDrhyTNc+XM1Ymq/Ac0+Iy36n37oKT7su/7OknLXTkrc46keZJ+0aBxVxtxH2yfK+lbki6NiD1V82u+rho28teMZh9mVU1eKunR7P7dki7K9mWapIuyeY02mteSbM9X5YSNB6rmFeV5GMk6SVdkZ1++Q9K+7JfUojwHI7L9ekl3SPrziHi8av6xto8fuK/KPjTfB+rnfTbMUDdV/t5zr6Ttkn4iaXo2v0vSTfHamUJbVDmTa4ukq6q2P0OV/2B7JP2TpEkF3YePSHpV0saq28Js2X3Zfm2V9L8lHdfAsV8i6XFVfnu+Npt3nSqhIEmTs+9rT/Z9PqNq22uz7R5T5bfDvF5DI+3DTyQ9V/V9XzfS66qA+/BFSduysa6XNL9q2yuz56dH0seKug/Z9P9Q5eMBq7crxPOgyskxu7Of052qvLX3F5L+IltuSd/I9m+LpK4CPgcj7cNNqlz8euBnoTubf0b2/d+Uvc6uzWsf6rnxySgAgFIr8luXAADUjaADAJQaQQcAKDWCDgBQagQdAKDUCDoAQKkRdACAUiPoAACl9v8Bj07bZn1BonEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_lr(W1, b1, W2, b2, W3, b3, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
